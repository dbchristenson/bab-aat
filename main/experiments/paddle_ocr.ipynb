{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from paddleocr import PaddleOCR, draw_ocr\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025/03/26 15:04:41] ppocr DEBUG: Namespace(help='==SUPPRESS==', use_gpu=False, use_xpu=False, use_npu=False, use_mlu=False, use_gcu=False, ir_optim=True, use_tensorrt=False, min_subgraph_size=15, precision='fp32', gpu_mem=500, gpu_id=0, image_dir=None, page_num=0, det_algorithm='DB', det_model_dir='C:\\\\Users\\\\User/.paddleocr/whl\\\\det\\\\en\\\\en_PP-OCRv3_det_infer', det_limit_side_len=4768, det_limit_type='max', det_box_type='quad', det_db_thresh=0.3, det_db_box_thresh=0.6, det_db_unclip_ratio=1.5, max_batch_size=10, use_dilation=False, det_db_score_mode='fast', det_east_score_thresh=0.8, det_east_cover_thresh=0.1, det_east_nms_thresh=0.2, det_sast_score_thresh=0.5, det_sast_nms_thresh=0.2, det_pse_thresh=0, det_pse_box_thresh=0.85, det_pse_min_area=16, det_pse_scale=1, scales=[8, 16, 32], alpha=1.0, beta=1.0, fourier_degree=5, rec_algorithm='SVTR_LCNet', rec_model_dir='C:\\\\Users\\\\User/.paddleocr/whl\\\\rec\\\\en\\\\en_PP-OCRv4_rec_infer', rec_image_inverse=True, rec_image_shape='3, 48, 320', rec_batch_num=6, max_text_length=25, rec_char_dict_path='c:\\\\Users\\\\User\\\\src\\\\bab-aat\\\\.venv\\\\Lib\\\\site-packages\\\\paddleocr\\\\ppocr\\\\utils\\\\en_dict.txt', use_space_char=True, vis_font_path='./doc/fonts/simfang.ttf', drop_score=0.5, e2e_algorithm='PGNet', e2e_model_dir=None, e2e_limit_side_len=768, e2e_limit_type='max', e2e_pgnet_score_thresh=0.5, e2e_char_dict_path='./ppocr/utils/ic15_dict.txt', e2e_pgnet_valid_set='totaltext', e2e_pgnet_mode='fast', use_angle_cls=True, cls_model_dir='C:\\\\Users\\\\User/.paddleocr/whl\\\\cls\\\\ch_ppocr_mobile_v2.0_cls_infer', cls_image_shape='3, 48, 192', label_list=['0', '180'], cls_batch_num=6, cls_thresh=0.9, enable_mkldnn=False, cpu_threads=10, use_pdserving=False, warmup=False, sr_model_dir=None, sr_image_shape='3, 32, 128', sr_batch_num=1, draw_img_save_dir='./inference_results', save_crop_res=False, crop_res_save_dir='./output', use_mp=False, total_process_num=1, process_id=0, benchmark=False, save_log_path='./log_output/', show_log=True, use_onnx=False, onnx_providers=False, onnx_sess_options=False, return_word_box=False, output='./output', table_max_len=488, table_algorithm='TableAttn', table_model_dir=None, merge_no_span_structure=True, table_char_dict_path=None, formula_algorithm='LaTeXOCR', formula_model_dir=None, formula_char_dict_path=None, formula_batch_num=1, layout_model_dir=None, layout_dict_path=None, layout_score_threshold=0.5, layout_nms_threshold=0.5, kie_algorithm='LayoutXLM', ser_model_dir=None, re_model_dir=None, use_visual_backbone=True, ser_dict_path='../train_data/XFUND/class_list_xfun.txt', ocr_order_method=None, mode='structure', image_orientation=False, layout=True, table=True, formula=False, ocr=True, recovery=False, recovery_to_markdown=False, use_pdf2docx_api=False, invert=False, binarize=False, alphacolor=(255, 255, 255), lang='en', det=True, rec=True, type='ocr', savefile=False, ocr_version='PP-OCRv4', structure_version='PP-StructureV2')\n"
     ]
    }
   ],
   "source": [
    "ocr = PaddleOCR(use_angle_cls=True, lang='en', det_limit_side_len=4768)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025/03/26 15:04:48] ppocr DEBUG: dt_boxes num : 575, elapsed : 2.6727089881896973\n",
      "[2025/03/26 15:04:50] ppocr DEBUG: cls num  : 575, elapsed : 1.3129804134368896\n",
      "[2025/03/26 15:05:00] ppocr DEBUG: rec_res num  : 575, elapsed : 9.90235185623169\n"
     ]
    }
   ],
   "source": [
    "\n",
    "img_path = \"C:\\\\Users\\\\User\\\\src\\\\bab-aat\\\\marine-process-imgs\\\\kraken-test_0.png\"\n",
    "result_lst = ocr.ocr(img_path, cls=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BBOX:  [[1378.0, 278.0], [1390.0, 278.0], [1390.0, 297.0], [1378.0, 297.0]]\n",
      "OCR + Confidence Tuple:  ('M', 0.5859618782997131)\n"
     ]
    }
   ],
   "source": [
    "print(\"BBOX: \", result_lst[0][0][0])\n",
    "print(\"OCR + Confidence Tuple: \", result_lst[0][0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bbox(result):\n",
    "    return result[0][0]\n",
    "\n",
    "def get_ocr(result):\n",
    "    return result[0][1][0]\n",
    "\n",
    "def get_confidence(result):\n",
    "    return result[0][1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup logging\n",
    "logging.basicConfig(filename='ocr.log', level=logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in result_lst[0]:\n",
    "    bbox = get_bbox(line)\n",
    "    text= get_ocr(line)\n",
    "    conf= get_confidence(line)\n",
    "\n",
    "    logging.log(logging.INFO, f\"bbox: {bbox}, text: {text}, confidence: {conf}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = result_lst[0]\n",
    "image = Image.open(img_path).convert('RGB')\n",
    "boxes = [line[0] for line in result]\n",
    "txts = [line[1][0] for line in result]\n",
    "scores = [line[1][1] for line in result]\n",
    "im_show = draw_ocr(image, boxes, txts, scores, font_path='../fonts/simfang.ttf')\n",
    "im_show = Image.fromarray(im_show)\n",
    "im_show.save('result.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image.open(img_path).convert('RGB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert PIL Image to OpenCV format (for drawing)\n",
    "image_cv = np.array(image)\n",
    "image_cv = image_cv[:, :, ::-1].copy()  # Convert RGB to BGR (OpenCV format)\n",
    "\n",
    "# Draw each bounding box and text at exact locations\n",
    "for box, text, score in zip(boxes, txts, scores):\n",
    "    # Convert box coordinates to numpy array\n",
    "    box_np = np.array(box, dtype=np.int32)\n",
    "\n",
    "    # Draw bounding box (green)\n",
    "    cv2.polylines(image_cv, [box_np], isClosed=True, color=(0, 255, 0), thickness=2)\n",
    "\n",
    "    # Calculate text position (top-left of bounding box)\n",
    "    text_x = box_np[0][0]\n",
    "    text_y = box_np[0][1] - 5  # Slightly above the box\n",
    "\n",
    "    # Ensure text doesn't go above the image\n",
    "    if text_y < 0:\n",
    "        text_y = box_np[0][1] + 20  # Move below if needed\n",
    "\n",
    "    # Draw text (red with white background for readability)\n",
    "    cv2.putText(image_cv,\n",
    "                f\"{text} ({score:.2f})\",\n",
    "                (text_x, text_y),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                0.5,  # Font scale\n",
    "                (0, 0, 255),  # Red text\n",
    "                1,  # Thickness\n",
    "                cv2.LINE_AA)\n",
    "\n",
    "    # Optional: Add white background behind text\n",
    "    (text_width, text_height), _ = cv2.getTextSize(f\"{text} ({score:.2f})\",\n",
    "                                                  cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                                                  0.5, 1)\n",
    "    cv2.rectangle(image_cv,\n",
    "                 (text_x, text_y - text_height - 2),\n",
    "                 (text_x + text_width, text_y + 2),\n",
    "                 (255, 255, 255),  # White\n",
    "                 -1)  # Filled rectangle\n",
    "    cv2.putText(image_cv,\n",
    "                f\"{text} ({score:.2f})\",\n",
    "                (text_x, text_y),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                0.5,\n",
    "                (0, 0, 255),  # Red text\n",
    "                1,\n",
    "                cv2.LINE_AA)\n",
    "\n",
    "# Convert back to PIL Image and save\n",
    "result_image = Image.fromarray(image_cv[:, :, ::-1])  # Convert BGR to RGB\n",
    "result_image.save('paddle_ocr_example.jpg')\n",
    "\n",
    "# Optional: Display the image\n",
    "result_image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_and_draw_ocr(image, boxes, txts, scores, output_path='paddle_ocr_example.jpg'):\n",
    "    \"\"\"\n",
    "    Processes OCR results and draws bounding boxes and text on the image.\n",
    "\n",
    "    Parameters:\n",
    "        image (PIL.Image.Image): The input image.\n",
    "        boxes (list): List of bounding boxes.\n",
    "        txts (list): List of recognized texts.\n",
    "        scores (list): List of confidence scores.\n",
    "        output_path (str): Path to save the output image.\n",
    "\n",
    "    Returns:\n",
    "        PIL.Image.Image: The processed image with bounding boxes and text.\n",
    "    \"\"\"\n",
    "    # Convert PIL Image to OpenCV format (for drawing)\n",
    "    image_cv = np.array(image)\n",
    "    image_cv = image_cv[:, :, ::-1].copy()  # Convert RGB to BGR (OpenCV format)\n",
    "\n",
    "    # Draw each bounding box and text at exact locations\n",
    "    for box, text, score in zip(boxes, txts, scores):\n",
    "        # Convert box coordinates to numpy array\n",
    "        box_np = np.array(box, dtype=np.int32)\n",
    "\n",
    "        # Draw bounding box (green)\n",
    "        cv2.polylines(image_cv, [box_np], isClosed=True, color=(0, 255, 0), thickness=2)\n",
    "\n",
    "        # Calculate text position (top-left of bounding box)\n",
    "        text_x = box_np[0][0]\n",
    "        text_y = box_np[0][1] - 5  # Slightly above the box\n",
    "\n",
    "        # Ensure text doesn't go above the image\n",
    "        if text_y < 0:\n",
    "            text_y = box_np[0][1] + 20  # Move below if needed\n",
    "\n",
    "        # Draw text (red with white background for readability)\n",
    "        cv2.putText(image_cv,\n",
    "                    f\"{text} ({score:.2f})\",\n",
    "                    (text_x, text_y),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    0.5,  # Font scale\n",
    "                    (0, 0, 255),  # Red text\n",
    "                    1,  # Thickness\n",
    "                    cv2.LINE_AA)\n",
    "\n",
    "        # Optional: Add white background behind text\n",
    "        (text_width, text_height), _ = cv2.getTextSize(f\"{text} ({score:.2f})\",\n",
    "                                                      cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                                                      0.5, 1)\n",
    "        cv2.rectangle(image_cv,\n",
    "                     (text_x, text_y - text_height - 2),\n",
    "                     (text_x + text_width, text_y + 2),\n",
    "                     (255, 255, 255),  # White\n",
    "                     -1)  # Filled rectangle\n",
    "        cv2.putText(image_cv,\n",
    "                    f\"{text} ({score:.2f})\",\n",
    "                    (text_x, text_y),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    0.5,\n",
    "                    (0, 0, 255),  # Red text\n",
    "                    1,\n",
    "                    cv2.LINE_AA)\n",
    "\n",
    "    # Convert back to PIL Image and save\n",
    "    result_image = Image.fromarray(image_cv[:, :, ::-1])  # Convert BGR to RGB\n",
    "    result_image.save(output_path)\n",
    "\n",
    "    # Optional: Display the image\n",
    "    result_image.show()\n",
    "\n",
    "    return result_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kraken_test_pdf = \"exp_imgs/kraken_test.pdf\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
